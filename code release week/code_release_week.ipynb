{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `f3dasm`: Framework for Data-Driven Design and Analysis of Structures and Materials \n",
    "*April 3rd, 2023* <br>\n",
    "*Code Release Week \\#1*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "**1. Project introduction**\n",
    "- 1.1 Overview\n",
    "- 1.2 Computational Framework\n",
    "- 1.3 Installation\n",
    "- 1.4 Getting started\n",
    "\n",
    "**2. Demonstration**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f3dasm is an attempt to unite data-driven design and analysis of structures of materials.\n",
    "More concretely, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Computational framework\n",
    "\n",
    "`f3dasm` is one python package that consists of 8 submodules:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use `f3dasm` to handle your design of experiments**\n",
    "\n",
    "Modules:\n",
    "- `f3dasm.design`\n",
    "- `f3dasm.experiment`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use `f3dasm` to compare models**\n",
    "\n",
    "Modules:\n",
    "- `f3dasm.machinelearning`\n",
    "- `f3dasm.optimization`\n",
    "- `f3dasm.sampling`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use `f3dasm` to generate data**\n",
    "\n",
    "Modules:\n",
    "- `f3dasm.functions`\n",
    "- `f3dasm.data`\n",
    "- `f3dasm.simulation`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System requirements\n",
    "`f3dasm` is purely Python code and compatible with:\n",
    "1. Python 3.7 to 3.10.\n",
    "2. the three major operations system (Linux, MacOS, Ubuntu).\n",
    "3. the default environment of Google Colab (Python 3.8, Linux) \n",
    "4. the `pip` package manager system.\n",
    "\n",
    "Installation instruction can be found in the documentation page under [Getting Started](https://bessagroup.github.io/F3DASM/gettingstarted.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We install the full version of `f3dasm`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting omegaconf==1.4.0\n",
      "  Downloading omegaconf-1.4.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: PyYAML in /home/martin/miniconda3/envs/f3dasm_env3/lib/python3.8/site-packages (from omegaconf==1.4.0) (6.0)\n",
      "Requirement already satisfied: six in /home/martin/miniconda3/envs/f3dasm_env3/lib/python3.8/site-packages (from omegaconf==1.4.0) (1.16.0)\n",
      "Installing collected packages: omegaconf\n",
      "  Attempting uninstall: omegaconf\n",
      "    Found existing installation: omegaconf 2.2.3\n",
      "    Uninstalling omegaconf-2.2.3:\n",
      "      Successfully uninstalled omegaconf-2.2.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "hydra-core 1.2.0 requires omegaconf~=2.2, but you have omegaconf 1.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed omegaconf-1.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Weird hot-fix only for Google Colab\n",
    "%pip install omegaconf==1.4.0\n",
    "\n",
    "try:\n",
    "    import f3dasm\n",
    "except ModuleNotFoundError:\n",
    "    %pip install -i https://test.pypi.org/simple/ f3dasm==0.9.2\n",
    "    import f3dasm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view the version and it's dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "f3dasm:\n",
      "        0.9.2\n",
      "\n",
      "System:\n",
      "    python: 3.8.15 | packaged by conda-forge | (default, Nov 22 2022, 08:49:35)  [GCC 10.4.0]\n",
      "executable: /home/martin/miniconda3/envs/f3dasm_env3/bin/python\n",
      "   machine: Linux-5.14.0-1059-oem-x86_64-with-glibc2.10\n",
      "\n",
      "Core package dependencies:\n",
      "        numpy: 1.23.5\n",
      "        scipy: 1.9.3\n",
      "       pandas: 1.5.2\n",
      "   matplotlib: 3.6.2\n",
      "       pathos: 0.3.0\n",
      "        hydra: 1.2.0\n",
      "     autograd: unknown\n",
      "\n",
      "Machine learning extension:\n",
      "   tensorflow: 2.11.0\n",
      "\n",
      "Optimization extension:\n",
      "       GPyOpt: 1.2.6\n",
      "          GPy: 1.10.0\n",
      "   tensorflow: 2.11.0\n",
      "        pygmo: 2.19.0\n",
      "\n",
      "Sampling extension:\n",
      "        SALib: 1.4.7\n"
     ]
    }
   ],
   "source": [
    "f3dasm.show_versions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distinction between python package and repository\n",
    "- The Python  PyPI package (`pip install f3dasm`) contains the code that is used when installing the package as a **user**. It contains only the `main` branch version.\n",
    "- The GitHub repository is mainly for **developers** and besides the package includes:\n",
    "  - Studies (more on that later)\n",
    "  - Test suite\n",
    "  - Documentation source\n",
    "  - Tutorial notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1.4 Getting started\n",
    "\n",
    "The package contains a lot of implementation for each of the blocks. However, the installation `f3dasm` is modular: you decide what you want to use or not.\n",
    "\n",
    "We can distinguish 3 ways of using `f3dasm`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Using `f3dasm` to handle your design of experiments\n",
    "*Have your own functions and modules and coat them in a `f3dasm` sauce to manage and scale-up your experiments!*\n",
    "\n",
    "The **core** package: contains the minimal installation to use `f3dasm` without extended features. \n",
    "Installed with `pip install f3dasm`\n",
    "\n",
    "The core package contains the following features:\n",
    "1. provide a way to parametrize your experiment with the **design-of-experiments** classes.\n",
    "2. provide the option to investigate their experiment by **sampling** and **optimizing** their design.\n",
    "3. provide the user guidance in **parallelizing** their program and ordering their data.\n",
    "4. give the user ways of deploying their **experiment** at the HPC (TORQUE system)\n",
    "\n",
    "The core package requires the following dependencies:\n",
    "- `numpy` and `scipy`: for numerical operations\n",
    "- `pandas`: for the representation of the design of experiments\n",
    "- `matplotlib`: for plotting\n",
    "- `hydra-core`: for deploying your experiment \n",
    "- `pathos`: for multiprocessing\n",
    "- `autograd`: for computing gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Using `f3dasm` to benchmark or compare models\n",
    "*Go fully `f3dasm`: use existing implementations to benchmark parts of the data-driven machine learning process!*\n",
    "\n",
    "You can solely use the core package, but it is advised to enrich `f3dasm` with its **extensions** \n",
    "\n",
    "The extensions contain the following features:\n",
    "1. provide various **implementations** to accommodate common machine learning workflows.\n",
    "2. provide **adapter** classes that link common machine learning libraries to `f3dasm` base classes. \n",
    "\n",
    "\n",
    "For each of the blocks, extensions can be installed to extend the choice of implementations. Installed with `pip install f3dasm[<name of extension>]`\n",
    "\n",
    "The following extensions are available:\n",
    "- **machinelearning**: containing various `tensorflow` related models\n",
    "- **sampling**: containing sampling strategies from `SALib`\n",
    "- **optimization**: containing various optimizers from `GPyOpt`, `pygmo` and `tensorflow`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Develop on `f3dasm`\n",
    "*Work hard, play hard: work towards making your implementations an official `f3dasm` extension!*\n",
    "\n",
    "If you want your implementation to be part of the `f3dasm` package, you can develop an adapter and/or implementation for `f3dasm`\n",
    "\n",
    "The **developement** package: contains the full installation plus requirements for developing on `f3dasm`. \n",
    "Installed with `pip install f3dasm[dev]`\n",
    "\n",
    "Information on how to contribute to `f3dasm` can be found [on the wiki page of the GitHub repository](https://github.com/bessagroup/F3DASM/wiki)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the past practical sessions, I have shown you how to use `f3dasm` to benchmark various parts of a data-driven machine learning process (**use-case #2**).\n",
    "\n",
    "Today I will show you how to use `f3dasm` to streamline your own data-driven process (**use-case #1**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import some other packages and set a seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import logging\n",
    "from pathos.helpers import mp  # For multiprocessing!\n",
    "import time # For ... timing!\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Set up your program with f3dasm\n",
    "\n",
    "Let's say we have a program that we want to execute. It is important that this could be **anything**. Like:\n",
    "- Calculate the loss of some compliance curve in topology optimization\n",
    "- Computing the mean stress and strain from some abaqus simulation\n",
    "- Benchmarking various regressors in a multi-fidelity setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the top level of your experiment, you will probably have a main function that accepts some arguments and returns the quantity of interest.\n",
    "\n",
    "Let's create such a function, just for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(a: float, b: float, c: float) -> float:    \n",
    "    functions = [f3dasm.functions.Rastrigin, f3dasm.functions.Levy, f3dasm.functions.Ackley]\n",
    "    y = []\n",
    "    for func in functions:\n",
    "        f = func(dimensionality=3, scale_bounds=np.tile([-1.,1.], (3,1)), seed=SEED)\n",
    "        time.sleep(.1)\n",
    "        y.append(f(np.array([a,b,c])).ravel()[0])\n",
    "\n",
    "    # Sum the values\n",
    "    out = sum(y)\n",
    "    logging.info(f\"Executed program with a={a:.3f}, b={b:.3f}, c={c:.3f}: \\t Result {out:.3f}\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are we seeing:\n",
    "- The program requires three floating points and returns a float as well.\n",
    "- It creates three 3D-benchmark functions, evaluates them sequentially and sums the results\n",
    "- We simulate some computational cost (0.1 seconds per evaluation) by calling the `time.sleep()` method\n",
    "- We write to a log\n",
    "\n",
    "> Note: `my_own_program` uses the integrated benchmark functions from `f3dasm`, but this could very well be one of your codes without any dependency on `f3dasm`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executing multiple experiments is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.random.uniform(size=(10,3))\n",
    "\n",
    "start_time = time.time()\n",
    "outputs = np.array([main(*input_vals) for input_vals in inputs])\n",
    "time_not_parallel = time.time() - start_time\n",
    "\n",
    "print(f\"It took {time_not_parallel:.5f} seconds to execute this for loop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save the values of `outputs` for later use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process (`main.py`) can be described with the following figure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/sequential.png\" alt=\"alt text\" width=\"30%\" height=\"30%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local parallelization\n",
    "\n",
    "If you are familiar with [multiprocessing](https://docs.python.org/3/library/multiprocessing.html), you might already know that we can speed-up this function by parellizing the internal for loop:\n",
    "\n",
    "We create a multiprocessing pool (`mp.Pool()`) where we map the functions to cores in our machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_parallel(a: float, b: float, c: float) -> float:\n",
    "    def evaluate_function(func, a, b, c):\n",
    "        f = func(dimensionality=3, scale_bounds=np.tile([-1.,1.], (3,1)))\n",
    "        y = f(np.array([a,b,c])).ravel()[0]\n",
    "        time.sleep(.1)\n",
    "        return y\n",
    "\n",
    "    functions = [f3dasm.functions.Rastrigin, f3dasm.functions.Levy, f3dasm.functions.Ackley]\n",
    "    with mp.Pool() as pool:\n",
    "        y = pool.starmap(evaluate_function, [(func, a, b, c) for func in functions])\n",
    "\n",
    "    # Sum the values\n",
    "    out = sum(y)\n",
    "\n",
    "    logging.info(f\"Executed program with a={a:.3f}, b={b:.3f}, c={c:.3f}: \\t Result: {out:.3f}\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executing this function will speed up the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.random.uniform(size=(10,3))\n",
    "\n",
    "start_time = time.time()\n",
    "outputs = np.array([main_parallel(*input_vals) for input_vals in inputs])\n",
    "time_parallel = time.time() - start_time\n",
    "\n",
    "print(f\"It took {time_parallel:.5f} seconds to execute this for loop\")\n",
    "print(f\"We are {time_not_parallel-time_parallel:.5f} seconds faster by parellelization!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process (`main_parallel.py`) can be described with the following figure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/parallel.png\" alt=\"alt text\" width=\"30%\" height=\"30%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale-up: challenges\n",
    "\n",
    "Now we would like to really scale things up. \n",
    "\n",
    "Q) What challenges lie along the way?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I asked ChatGPT:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **1. Experiment design and analysis**: As the complexity of the experiment increases, it becomes more difficult to design experiments that are robust and reproducible, and to analyze the results in a meaningful way. This can lead to issues with experimental design, parameter tuning, and statistical analysis.\n",
    "\n",
    "- **2. Parallelization**: As experiments become larger, it may be necessary to parallelize or distribute the computations across multiple machines or nodes in order to reduce the overall runtime. This introduces additional challenges such as synchronization between distributed processes.\n",
    "\n",
    "- **3. Managing data**: As the volume of data generated by an experiment increases, it becomes more difficult to manage and store that data. This can lead to issues with data corruption, loss, or inconsistency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where `f3dasm` is a helping hand!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Experiment design and analysis\n",
    "\n",
    "We can create a `f3dasm.DesignSpace` to capture the variables of interest:\n",
    "- A `f3dasm.DesignSpace` consists of an input and output list of `f3dasm.Parameter` objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_a = f3dasm.ContinuousParameter(name='a', lower_bound=-1., upper_bound=1.)\n",
    "param_b = f3dasm.ContinuousParameter(name='b', lower_bound=-1., upper_bound=1.)\n",
    "param_c = f3dasm.ContinuousParameter(name='c', lower_bound=-1., upper_bound=1.)\n",
    "param_out = f3dasm.ContinuousParameter(name='y')\n",
    "\n",
    "design = f3dasm.DesignSpace(input_space=[param_a, param_b, param_c], output_space=[param_out])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create an object to store the experiments: `f3dasm.ExperimentData`, but we can also **sample from this designspace**\n",
    "We do that with the `f3dasm.sampling` submodule:\n",
    "\n",
    "> Note that this submodule offers an extension (`f3dasm[sampling]`) that include sampling strategies from `SALib` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the sampler object\n",
    "sampler = f3dasm.sampling.RandomUniform(design=design, seed=SEED)\n",
    "\n",
    "data: f3dasm.ExperimentData = sampler.get_samples(numsamples=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data object is under the hood a pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `y` values are NaN because we haven't evaluate our experiment yet! Let's do that:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handy: we can retrieve the input columns of a specific row as a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.get_inputdata_by_index(index=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unpacking the values as arguments of our experiment creates the same results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(data.get_number_of_datapoints()):\n",
    "    value = main_parallel(**data.get_inputdata_by_index(index))\n",
    "    data.set_outputdata_by_index(index, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our data-object is filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process can be described with the following figure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/single_node.png\" alt=\"alt text\" width=\"50%\" height=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`f3dasm` can handle the experiment distribution. \n",
    "\n",
    "In order to set this up, navigate to a folder where you want to create your experiment and run `f3dasm.experiment.quickstart()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'll not run this command because this is a demo\n",
    "\n",
    "# f3dasm.experiment.quickstart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates the following files and folders:\n",
    "\n",
    "```\n",
    "└── my_experiment \n",
    "    ├── main.py\n",
    "    ├── config.py\n",
    "    ├── config.yaml\n",
    "    ├── default.yaml\n",
    "    ├── pbsjob.sh\n",
    "    └── README.md\n",
    "    └── hydra/job_logging\n",
    "        └── custom_script.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without going to much in detail, the following things have already been set up automatically:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logging**\n",
    "- `hydra` (and the `custom_script.py`) take care of all (multiprocess) logging\n",
    "- including writing across nodes when executing arrayjobs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameter storage**\n",
    "- `config.yaml`, `config.py` and `default.yaml` can be used for easy reproducibility and parameter tuning of your experiment!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parallelization**\n",
    "- `pbsjob.sh` can be used to execute your `main.py` file on the HPC, including array-jobs.\n",
    "\n",
    "example:\n",
    "```\n",
    "qsub pbsjob.sh\n",
    "qsub pbsjob.sh -t 0-10\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving data**\n",
    "- `hydra` creates a new `outputs/<HPC JOBID>/` directory that saves all output files, logs and settings when executing `main.py`\n",
    "- When executing arrayjobs, all arrayjobs write to the same folder!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Parallelization\n",
    "\n",
    "Let's recall: our single node process with `f3dasm.ExperimentData` can be abstracted by the following image:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"single_node.png\" alt=\"alt text\" width=\"50%\" height=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallelizing the **outer loop** is more difficult, but we can do that across nodes with help of the `f3dasm.experiment.JobQueue`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_queue = f3dasm.experiment.JobQueue(filename='my_jobs')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fill the queue with the rows of the `f3dasm.ExperimentData` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_queue.create_jobs_from_experimentdata(data)\n",
    "job_queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 jobs have been added and they are all up for grabs!\n",
    "\n",
    "Let's first write this to disk so multiple nodes can access it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_queue.write_new_jobfile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A node can grab the first available job in the queue with the `get()` method:\n",
    "The file is locked when accessing the information from the JSON file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = job_queue.get()\n",
    "print(f\"The first open job_id is {job_id}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After returning the `job_id`, the lock is removed and the job is changed to `in progress`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_queue.get_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a new node asks a new job, it will return the next open job in line!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_id = job_queue.get()\n",
    "print(f\"The first open job_id is {job_id}!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a job is finished, you can mark it finished or with an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_queue.mark_finished(index=0)\n",
    "job_queue.mark_error(index=1)\n",
    "\n",
    "job_queue.get_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now change our simple script to handle multiprocessing across nodes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_queue = f3dasm.experiment.JobQueue(filename='my_jobs2')\n",
    "job_queue.create_jobs_from_experimentdata(data)\n",
    "\n",
    "job_queue.write_new_jobfile()\n",
    "\n",
    "data.store('data')\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        jobnumber = job_queue.get()\n",
    "    except f3dasm.experiment.NoOpenJobsError:\n",
    "        break\n",
    "    \n",
    "    data = f3dasm.design.load_experimentdata('data')\n",
    "    args = data.get_inputdata_by_index(jobnumber)\n",
    "\n",
    "    value = main_parallel(**data.get_inputdata_by_index(jobnumber))\n",
    "    data.set_outputdata_by_index(jobnumber, value)\n",
    "\n",
    "    data.store('data')\n",
    "\n",
    "    job_queue.mark_finished(jobnumber)\n",
    "\n",
    "data.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/jobqueue.png\" alt=\"alt text\" width=\"50%\" height=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Managing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you don't want to write directly to the `ExperimentData` file. Perhaps the output is not a simple set of values, or you want to do some post-processing.\n",
    "This is where the `f3dasm.Filehandler` comes in handy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/jobqueue_filehandler.png\" alt=\"alt text\" width=\"80%\" height=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "03276761335d5ee93b82dc97db1addd68180a543fb0cacb8af76ec058b1972b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
